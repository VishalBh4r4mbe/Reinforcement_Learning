{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ_ACTION_SPACE = env.action_space.n\n",
    "SZ_OBS_SPACE = env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIteration:\n",
    "    def __init__(self,env,gamma=1.0):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.SZ_ACTION_SPACE = self.env.action_space.n\n",
    "        self.SZ_OBS_SPACE = self.env.observation_space.n\n",
    "        self.policy = np.random.choice(env.nA,size = (env.nS))\n",
    "    def policy_evaluation(self):\n",
    "        v = np.zeros(self.env.nS)\n",
    "        epsilon = 1e-13\n",
    "        while True:\n",
    "            prev_v = np.copy(v)\n",
    "            for s in range(self.env.nS):\n",
    "                policy_a = self.policy[s]\n",
    "                v[s] = sum([p*(r_ + self.gamma*prev_v[s_]) for p, s_,r_,_ in self.env.P[s][policy_a]])\n",
    "            if(np.sum((np.fabs(prev_v-v)))<epsilon):\n",
    "                break\n",
    "        return v\n",
    "    def policy_improvement(self,v):\n",
    "        policy = np.random.choice(self.env.nA,size = self.env.nS)\n",
    "        for s in range(self.env.nS):\n",
    "            q_sa = np.zeros(self.env.nA)\n",
    "            for a in range(self.env.nA):\n",
    "                q_sa[a] = sum([p* (r_+self.gamma*v[s_]) for p, s_,r_,_ in self.env.P[s][a]])\n",
    "            policy[s] = np.argmax(q_sa)\n",
    "        return policy\n",
    "    def run(self,iterations=100000):\n",
    "        for i in range(iterations):\n",
    "            # print(f\"Iteration {i+1} started\")\n",
    "\n",
    "            old_policy = np.copy(self.policy)\n",
    "            V = self.policy_evaluation()\n",
    "            # print(V)\n",
    "            self.policy = np.copy(self.policy_improvement(V))\n",
    "            if np.array_equal(old_policy,self.policy):\n",
    "                print(\"Converged at iteration {}\".format(i+1))\n",
    "                break\n",
    "    def evaluate(self,episodes,render=False,verbose=False):\n",
    "        total_reward = 0\n",
    "        for i in range(episodes):\n",
    "            obs = self.env.reset()\n",
    "            done = False\n",
    "            step = 0\n",
    "            ep_reward=0\n",
    "            while True:\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                obs,reward,done,_ = self.env.step(int(self.policy[obs]))\n",
    "                ep_reward += reward\n",
    "                step += 1\n",
    "                if done:\n",
    "                    if verbose:\n",
    "                        print(f\"Took {step} steps\")\n",
    "                    total_reward += ep_reward\n",
    "                    break\n",
    "        return total_reward/episodes        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 12\n",
      "0.8875\n"
     ]
    }
   ],
   "source": [
    "env_name = \"FrozenLake8x8-v0\"\n",
    "env = gym.make(env_name)\n",
    "pi = PolicyIteration(env)\n",
    "pi.run()\n",
    "print(pi.evaluate(10000))\n",
    "# print(pi.policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
